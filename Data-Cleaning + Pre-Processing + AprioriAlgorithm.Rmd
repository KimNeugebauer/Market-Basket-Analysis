---
title: "Data Cleaning and Pre-Processing, applying apriori algorithm - Market Basket Analysis"
author: "KimN"
date: "4 11 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading Data and Libraries

```{r loading data, message = FALSE, results = 'hide'}
### Connecting data base and checking data

library(DBI)
library(RMySQL)
library(dplyr)
library(ggplot2)
library(arules)


# 2. Connecting to db
db_user <- 'data_student_berlin'
db_password <- 'waai_has_shitty_internet'
db_name <- 'pricehub'
db_host <- '34.89.228.59' # for local access
db_port <- 3306
mydb <-  dbConnect(MySQL(), user = db_user, password = db_password,
                   dbname = db_name, host = db_host, port = db_port)

# 3. Read data from db
db_table <- 'line_item'
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
line_item <-  fetch(rs, n = -1)

##Import df 'orders'
db_table <- 'orders'
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
orders <-  fetch(rs, n = -1)

##Import df 'products'
db_table <- 'products'
s <- paste0("select * from ", db_table)
rs <- dbSendQuery(mydb, s)
products <-  fetch(rs, n = -1)
on.exit(dbDisconnect(mydb))
```

## Data Cleaning and filtering

```{r factoring, eval = FALSE, message = FALSE}

as.factor(orders$state)
```

```{r data cleaning}
## joining line item and orders

join1 <- inner_join(line_item, orders, by="id_order")

head(join1)


## joining previous with products

join_full <- inner_join(join1, products, by="sku")


## filtering out non completed orders

join_full <- join_full %>%  
              filter(join_full$state == "Completed")

summary(join_full)
dim(join_full)

## create column with unit price * quantity

join_full <- join_full %>% 
  mutate(Paid_per_product = unit_price * product_quantity)
```


## Grouping by id_order, calculating difference in the total amount paid, keeping only orders with price diff/total paid < 0.3

```{r grouping}
diff_table <- join_full %>% 
  group_by(id_order) %>%
  summarise(paid_per_order = sum(Paid_per_product),
            total_paid = mean(total_paid)) %>% 
  mutate(diff_total_paid = abs(total_paid-paid_per_order),
         ratio = diff_total_paid/total_paid) %>% 
  filter(ratio < 0.3)


## creating out of line_item a table that contains only relevant rows for id_order

final_table <- line_item[line_item$id_order %in% diff_table$id_order, ]


## excluding transactions of size 1

not1 <- final_table %>% 
  group_by(id_order) %>% 
  count(id_order)


not1 <- not1 %>% filter(n != 1)

transactions_not1 <- final_table[final_table$id_order %in% 
                                          not1$id_order, ]
```

## Creating the transactional file

```{r transactional file}

## exchanging sku with name of products

transactions_not1_name <- transactions_not1 %>% 
        left_join(products, by ="sku")


transactions_not1_name <- transactions_not1_name %>% 
        select(id_order,name_en)


## deleting missing values

sum(is.na(transactions_not1_name))
transactions_not1_name <- na.omit(transactions_not1_name)


## taking only id_order and sku into the transactional file

transactional_file <- transactions_not1 %>% select(id_order, sku)
```

## Transforming transactional file using read.transactions

```{r read.transactions}
write.csv(transactional_file, 
          file = "transactional_file.csv",
          row.names=FALSE)


large_transactions <- read.transactions(
  "transactional_file.csv",
  format = "single",
  cols = c(1,2),
  header = TRUE,
  sep = ","
)

large_transactions
inspect(head(large_transactions))
```

## Investigating the data

```{r investigating large transactional file}

## Getting to know the large transactions file

large_transactions_name <- large_transactions

large_transactions_name
inspect(head(large_transactions_name))
length(large_transactions_name)
size(head(large_transactions_name, 100))
```

## Plotting and imaging the large transactions file

```{r plotting}
itemFrequencyPlot(large_transactions_name)

itemFrequencyPlot(large_transactions_name, 
                  topN = 15, 
                  type = c("absolute"), 
                  col = rainbow(20),
                  horiz = TRUE,
                  xlab = "Item Frequency, absolute values")


image(large_transactions_name)
```

## Cross Table of items purchased together, also testing for Chi-Squared

```{r cross table}
cross_table <- crossTable(large_transactions_name, 
                          sort = TRUE)

cross_table[1:5,1:5]


cross_table_chi <-  crossTable(large_transactions_name, measure = "chi")

head(cross_table_chi[1:5])
```

## Applying the Apriori Algorithm

```{r apriori}

rules <- apriori(large_transactions_name, 
                 parameter = list(supp = 0.001,   # 5 rules
                                  conf = 0.6, 
                                  target = "rules"))

rules <- apriori(large_transactions_name, 
                 parameter = list(supp = 0.0005,   # 48 rules
                                  conf = 0.5, 
                                  target = "rules"),
                 control = list())

rules
inspect(rules[1:10])
summary(rules)
```

## Removing redundant rules with is.redundant ()

```{r redundant rules}
redundant_rules <- is.redundant(rules)
summary(redundant_rules)

rules <- rules[!redundant_rules]
length(rules)
```

## Removing redundant rules second option

```{r removing redundant rules second option}
redundant_rules <- which(colSums(is.subset(rules)) >1)
length(redundant_rules)

rules <- rules[- redundant_rules]
length(rules)
```

## Checking on frequent items in the basket, confidence and lift parameters

```{r freuquent items}
frequentItems <- eclat (large_transactions_name, 
                        parameter = list(supp = 0.01, maxlen = 15))

inspect(sort(frequentItems, 
             decreasing = TRUE, by = "support")[1:5])



rules_conf <- sort(rules, by = "confidence", desc = TRUE)
inspect(rules_conf[1:10])

rules_lift <- sort(rules, by = "lift", desc = TRUE)
inspect(rules_lift[1:10])
```
